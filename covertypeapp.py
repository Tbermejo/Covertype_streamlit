import streamlit as st
import pandas as pd
import numpy as np
import gzip
import pickle
import plotly.express as px
import seaborn as sns
import matplotlib.pyplot as plt
from ucimlrepo import fetch_ucirepo

# Configuraci贸n de la p谩gina
st.set_page_config(page_title="Dataset Forest Covertype", layout="wide")

def cargar_datos():
    """Carga el dataset covertype y lo formatea."""
    covertype = fetch_ucirepo(id=31)
    X = covertype.data.features
    y = covertype.data.targets
    dataset = pd.concat([X, y], axis=1)
    dataset.columns = list(X.columns) + ['target']
    dataset["target"] = dataset["target"].astype(str)
    return dataset

# Cargar el dataset
dataset = cargar_datos()
numeric_columns = dataset.select_dtypes(include=["float64", "int64"]).columns
categorical_columns = dataset.select_dtypes(include=["object", "category"]).columns

# Barra lateral: Selecci贸n de cap铆tulos
st.sidebar.title(" Cap铆tulos")
capitulo = st.sidebar.radio("Selecciona un cap铆tulo:", [
    "Introducci贸n",
    "Exploraci贸n de Datos",
    "Visualizaci贸n de Datos",
    "Modelos de Clasificaci贸n"
])
# Diccionario con nombres de modelos y sus rutas
model_paths = {
    "Modelo K Neighbors Classifier": "best_model_trained_classifier.pkl.gz",
    "Modelo Red Neuronal": "model_trained_neuronal.pkl.gz",
    
}

# Sidebar para elegir el modelo
modelo_seleccionado = st.sidebar.selectbox("Seleccione el modelo de clasificaci贸n", list(model_paths.keys()))

# Cargar el modelo seleccionado
@st.cache_resource
def cargar_modelo(ruta):
    with gzip.open(ruta, "rb") as file:
        return pickle.load(file)

modelo = cargar_modelo(model_paths[modelo_seleccionado])

st.title("M茅todos de clasificaci贸n para el Dataset Covertype")

if capitulo == "Introducci贸n":
    st.write("""El dataset Covertype proporciona informaci贸n de cuatro 谩reas naturales localizadas en el Parque Natural Roosevelt en el Norte de Colorado, Estados Unidos.
    El objetivo es clasificar el tipo de cobertura forestal seg煤n variables cartogr谩ficas como: """)

# Definir los datos de las variables en un DataFrame
    variables_info = pd.DataFrame({
        "Variable": [
            "Elevaci贸n", "Orientaci贸n", "Pendiente", "Distancia_horizontal_a_hidrolog铆a",
            "Distancia_vertical_a_hidrolog铆a", "Distancia_horizontal_a_carreteras", 
            "Hillshade_9am", "Hillshade_Noon", "Hillshade_3pm", 
            "Horizontal_Distance_To_Fire_Point", "rea silvestre 1", 
            "rea silvestre 2", "rea silvestre 3", "rea silvestre 4", 
            "Tipo de suelo 1-40"
        ],
        "Descripci贸n": [
            "Elevaci贸n en metros.",
            "Orientaci贸n en grados de azimut.",
            "Pendiente en grados.",
            "Distancia horizontal a las caracter铆sticas de agua superficial m谩s cercanas.",
            "Distancia vertical a las caracter铆sticas de agua superficial m谩s cercanas.",
            "Distancia horizontal a la carretera m谩s cercana.",
            "ndice de sombra de las colinas a las 9 a. m., solsticio de verano. Valor de 255.",
            "ndice de sombra de las colinas al mediod铆a, solsticio de verano. Valor de 255.",
            "ndice de sombra de las colinas a las 3 p. m., solsticio de verano. Valor de 255.",
            "Distancia horizontal a los puntos de ignici贸n de incendios forestales m谩s cercanos.",
            "rea silvestre Rawah.",
            "rea silvestre Neota.",
            "rea silvestre Comanche Peak.",
            "rea silvestre Cache la Poudre.",
            "Tipos de suelo categorizados del 1 al 40."
        ]
    })

    
    st.write("###  Variables del Dataset")
    st.table(variables_info)
    
# Variable objetivo
    st.write("""Donde la variable objetivo es el tipo de cobertura forestal, descrita a continuaci贸n:""")

    variable_obj = pd.DataFrame({
        "Tipo de cobertura": [
            "Spruce/Fir - P铆cea/abeto","Lodgepole Pine - Pino contorta","Ponderosa Pine - Pino ponderosa",
            "Cottonwood/Willow - lamo de Virginia/sauce","Aspen - lamo tembl贸n","Douglas-fir - Abeto de Douglas","Krummholz"
        ],

        "ID": [
            "1","2","3","4","5","6","7"
        ]
    })

    st.write("###  Tipo de coberturas - Variable objetivo")
    st.table(variable_obj)

    st.write("""Fuente: Blackard, J. (1998). Covertype [Dataset]. UCI Machine Learning Repository. https://doi.org/10.24432/C50K5N.""")
elif capitulo == "Exploraci贸n de Datos":
    st.header(" Exploraci贸n de Datos")

    if st.sidebar.checkbox("Mostrar primeras filas"):
        n_rows = st.sidebar.slider("N煤mero de filas a mostrar:", 1, len(dataset), 5)
        st.write(f"### Primeras {n_rows} filas del dataset")
        st.write(dataset.head(n_rows))
    
    if st.sidebar.checkbox("Mostrar informaci贸n general"):
        st.write("### Informaci贸n general del dataset")
        st.write("#### Tipos de datos y valores nulos:")
        st.write(dataset.dtypes)
        st.write("#### Valores nulos por columna:")
        st.write(dataset.isnull().sum())
        st.write("#### Estad铆sticas descriptivas:")
        st.write(dataset.describe())

elif capitulo == "Visualizaci贸n de Datos":
    st.header(" Visualizaci贸n de Datos")

    chart_type = st.sidebar.selectbox(
        "Selecciona el tipo de gr谩fico:",
        ["Dispersi贸n", "Distribuci贸n variable objetivo",
         "Mapa de correlaci贸n"]
    )

    if chart_type == "Dispersi贸n" and len(numeric_columns) > 1:
        x_var = st.sidebar.selectbox("Variable X:", numeric_columns)
        y_var = st.sidebar.selectbox("Variable Y:", numeric_columns)
        st.write(f"### Gr谩fico de dispersi贸n: {x_var} vs {y_var}")
        fig = px.scatter(dataset, x=x_var, y=y_var, title=f"Dispersi贸n de {x_var} vs {y_var}")
        st.plotly_chart(fig)
        
    elif chart_type == "Distribuci贸n Variable objetivo":
        st.write("### Distribuci贸n de la variable objetivo (Cover_Type)")
        fig, ax = plt.subplots(figsize=(8, 6))
        sns.countplot(data=dataset, x='target', palette='viridis', ax=ax)
        ax.set_title("Distribuci贸n de la variable objetivo (Cover_Type)")
        ax.set_xlabel("Tipo de cobertura")
        ax.set_ylabel("Frecuencia")
        st.pyplot(fig)
    
    elif chart_type == "Mapa de correlaci贸n" and len(numeric_columns) > 1:
        st.write("### Mapa de correlaci贸n")
        corr = dataset.corr()
        fig, ax = plt.subplots(figsize=(14, 10))
        sns.heatmap(corr, annot=False, cmap="coolwarm", ax=ax)
        ax.set_title("Mapa de correlaci贸n")
        st.pyplot(fig)
    
elif capitulo == "Modelos de Clasificaci贸n":
    st.header(" KNeighborsClassifier")
    st.write("Aqu铆 se implementar谩 un modelo previamente entrenado por el m茅todo KNeighborsClassifier.")

    #Informaci贸n del modelo ---
    st.write(" Par谩metros del Modelo")

    if modelo is not None:
        modelo_tipo = type(modelo).__name__
        st.write(f" **Tipo de modelo:** {modelo_tipo}")

        # Si el modelo es un pipeline, extraer la 煤ltima etapa (el modelo real)
        if isinstance(modelo, Pipeline):
            modelo_real = modelo.named_steps.get("reg")  # Extrae la etapa "reg" (el regresor)
            scaler_usado = modelo.named_steps.get("scaler")
        else:
            modelo_real = modelo
            scaler_usado = None

        if modelo_real:
            st.sidebar.write(f" **Modelo en uso:** {type(modelo_real).__name__}")
    
        if scaler_usado:
            st.sidebar.write(f"锔 **Escalador aplicado:** {type(scaler_usado).__name__}")

        try:
            params = modelo_real.get_params()  # Obtener hiperpar谩metros del modelo real
            st.write("###  Hiperpar谩metros Ajustados:")

        # Diccionario con descripciones de los hiperpar谩metros m谩s comunes
            hyperparam_descriptions = {
                "alpha": "Regularizaci贸n: controla la penalizaci贸n sobre los coeficientes.",
                "l1_ratio": "Controla la mezcla entre L1 (Lasso) y L2 (Ridge) en ElasticNet.",
                "kernel": "Funci贸n del n煤cleo utilizada en modelos Kernel.",
                "C": "Inverso de la regularizaci贸n en modelos como SVR (mayor = menos penalizaci贸n).",
                "gamma": "Par谩metro del n煤cleo en modelos como SVR y Kernel Ridge.",
                "n_estimators": "N煤mero de 谩rboles en modelos de Random Forest.",
                "max_depth": "Profundidad m谩xima del 谩rbol en Random Forest.",
                "learning_rate": "Velocidad de aprendizaje en modelos basados en boosting."
            }

            for key, value in params.items():
                explanation = hyperparam_descriptions.get(key, "Sin descripci贸n disponible")
                st.write(f" **{key}:** {value}")
                st.caption(f" {explanation}")  

        except Exception as e:
            st.error(f"锔 Error al obtener los hiperpar谩metros del modelo: {e}")


            # Mostrar MAE en la barra lateral de Streamlit
        st.write("###  Error Medio Absoluto (MAE):")
        if isinstance(accuracy, (int, float)):  # Verifica si el MAE es num茅rico
            st.write(f" **accuracy:** {accuracy:.4f}")
            st.caption(" M茅trica que indica la precisi贸n del modelo.")
        else:
            st.warning("MAE del modelo cargado: accuracy")
        
            #Mostrar coeficientes si est谩n disponibles
        st.write("###  Coeficientes del Modelo:")
        if hasattr(modelo_real, "coef_"):
            coeficientes = modelo_real.coef_
            st.sidebar.write(coeficientes)
        else:
            st.sidebar.warning("锔 Este modelo no tiene coeficientes disponibles.")

    else:
        st.sidebar.warning("锔 Modelo no cargado. No se pueden mostrar los par谩metros.")





    # Definir las caracter铆sticas que necesita el modelo
feature_names = [
    "Elevation", "Aspect", "Slope", "Horizontal_Distance_To_Hydrology",
    "Vertical_Distance_To_Hydrology", "Horizontal_Distance_To_Roadways",
    "Horizontal_Distance_To_Fire_Point"
]

#Rango de valores para las variables
variables_range = {
    "Elevation": {"min": 1850, "max": 4000, "desc": "Elevaci贸n en metros"},
    "Aspect": {"min": 0, "max": 360, "desc": "Orientaci贸n en grados de azimut"},
    "Slope": {"min": 0, "max": 60, "desc": "Pendiente en grados"},
    "Horizontal_Distance_To_Hydrology": {"min": 0, "max": 1350, "desc": "Distancia a cuerpos de agua"},
    "Vertical_Distance_To_Hydrology": {"min": -150, "max": 550, "desc": "Diferencia de altura cuerpos de agua"},
    "Horizontal_Distance_To_Roadways": {"min": 0, "max": 7000, "desc": "Distancia a la carretera"},
    "Horizontal_Distance_To_Fire_Point": {"min": 0, "max": 7000, "desc": "Distancia a punto de incendios"}
}

#Ingresar variables para clasificaci贸n
st.sidebar.header(" Ingrese los valores para clasificar el tipo de cobertura:")

valores_usuario = []
for col, info in variables_range.items():
    valor = st.sidebar.slider(
        f"{col} - {info['desc']}",
        min_value=float(info["min"]),
        max_value=float(info["max"]),
        value=(info["min"] + info["max"]) / 2
    )
    valores_usuario.append(valor)

# Bot贸n de clasificaci贸n
if st.sidebar.button(" Clasificar Cobertura"):
    if modelo is not None:
        entrada = np.array(valores_usuario).reshape(1, -1)  # Convertir a matriz

        # Verificar si el modelo es una red neuronal
        if hasattr(modelo, "predict_proba"):  
            entrada = entrada.astype(np.float32)  # Convertir a float32 si es necesario

        try:
            prediccion = modelo.predict(entrada)  # Hacer la predicci贸n

            # Si la predicci贸n es un array de probabilidades, convertir a clase
            if len(prediccion.shape) > 1 and prediccion.shape[1] > 1:
                prediccion = np.argmax(prediccion, axis=1)  # Tomar la clase con mayor probabilidad

            st.success(f" Tipo de cobertura clasificada: {int(prediccion[0])}")  
        except Exception as e:
            st.error(f"锔 Error al hacer la predicci贸n: {e}")
    else:
        st.error("锔 No se pudo hacer la clasificaci贸n porque el modelo no est谩 cargado.")



