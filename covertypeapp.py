import streamlit as st
import pandas as pd
import numpy as np
import gzip
import pickle
import plotly.express as px
import seaborn as sns
import matplotlib.pyplot as plt
from ucimlrepo import fetch_ucirepo
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import train_test_split
from PIL import Image

# Configuraci√≥n de la p√°gina
st.set_page_config(page_title="Dataset Forest Covertype", layout="wide")

def cargar_datos():
    """Carga el dataset covertype y lo formatea."""
    covertype = fetch_ucirepo(id=31)
    X = covertype.data.features
    y = covertype.data.targets
    dataset = pd.concat([X, y], axis=1)
    dataset.columns = list(X.columns) + ['target']
    dataset["target"] = pd.to_numeric(dataset["target"], errors="coerce")
    dataset["target"] = dataset["target"].apply(lambda x: x if x in [1, 2] else 3)
    feature_names = [
        "Elevation", "Aspect", "Slope", "Horizontal_Distance_To_Hydrology",
        "Vertical_Distance_To_Hydrology", "Horizontal_Distance_To_Roadways",
        "Horizontal_Distance_To_Fire_Point"
    ]
    feature_names = [col for col in feature_names if col in X.columns]  
    print(f"üìå Variables seleccionadas: {feature_names}")  # Verificar qu√© columnas se usan

    #X = X[feature_names]
    dataset["target"] = dataset["target"].astype(str)
    return dataset

# Cargar el dataset
dataset = cargar_datos()
X = dataset.drop(columns=["target"])  # Variables predictoras
y = dataset["target"]  # Variable objetivo

numeric_columns = dataset.select_dtypes(include=["float64", "int64"]).columns
categorical_columns = dataset.select_dtypes(include=["object", "category"]).columns

# Barra lateral: Selecci√≥n de cap√≠tulos
st.sidebar.title("üìö Cap√≠tulos")
capitulo = st.sidebar.radio("Selecciona un cap√≠tulo:", [
    "Introducci√≥n",
    "Exploraci√≥n de Datos",
    "Visualizaci√≥n de Datos",
    "Modelos de Clasificaci√≥n"
])
# Diccionario con nombres de modelos y sus rutas
model_paths = {
    "Modelo K Nearest Neighbors": "best_model_trained_classifier_new.pkl.gz",
    "Modelo Red Neuronal": "best_model (2).pkl.gz",
    
}

# Sidebar para elegir el modelo
modelo_seleccionado = st.sidebar.selectbox("Seleccione el modelo de clasificaci√≥n", list(model_paths.keys()))

# Cargar el modelo seleccionado
@st.cache_resource
def cargar_modelo(ruta):
    with gzip.open(ruta, "rb") as file:
        return pickle.load(file)

modelo = cargar_modelo(model_paths[modelo_seleccionado])

st.title("M√©todos de clasificaci√≥n para el Dataset Covertype")

if capitulo == "Introducci√≥n":
    st.write("""El dataset Covertype proporciona informaci√≥n de cuatro √°reas naturales localizadas en el Parque Natural Roosevelt en el Norte de Colorado, Estados Unidos.
    El objetivo es clasificar el tipo de cobertura forestal seg√∫n variables cartogr√°ficas como: """)

    st.write(f"üìä **El dataset tiene {dataset.shape[0]} filas y {dataset.shape[1]} columnas.**")
    
# Definir los datos de las variables en un DataFrame
    variables_info = pd.DataFrame({
        "Variable": [
            "Elevaci√≥n", "Orientaci√≥n", "Pendiente", "Distancia_horizontal_a_hidrolog√≠a",
            "Distancia_vertical_a_hidrolog√≠a", "Distancia_horizontal_a_carreteras",  
            "Horizontal_Distance_To_Fire_Point"
        ],
        "Descripci√≥n": [
            "Elevaci√≥n en metros.",
            "Orientaci√≥n en grados de azimut.",
            "Pendiente en grados.",
            "Distancia horizontal a las caracter√≠sticas de agua superficial m√°s cercanas.",
            "Distancia vertical a las caracter√≠sticas de agua superficial m√°s cercanas.",
            "Distancia horizontal a la carretera m√°s cercana.",
            "Distancia horizontal a los puntos de ignici√≥n de incendios forestales m√°s cercanos."
        ]
    })

    
    st.write("### üìã Variables del Dataset")
    st.table(variables_info)
    
# Variable objetivo
    st.write("""Donde la variable objetivo es el tipo de cobertura forestal. Para el ejercicio, se realiz√≥ una reclasificaci√≥n en tres tipos 
, las cuales de describen a continuaci√≥n:""")

    variable_obj = pd.DataFrame({
        "Tipo de cobertura": [
            "Spruce/Fir - P√≠cea/abeto","Lodgepole Pine - Pino contorta","Otras"
    
        ],

        "ID": [
            "1","2","3"
        ]
    })

    st.write("### üìã Tipo de coberturas - Variable objetivo")
    st.table(variable_obj)

    st.write("üìä **Distribuci√≥n de clases despu√©s de la reclasificaci√≥n:**")
    st.write(y.value_counts())
    
    class_distribution = y.value_counts()
    fig, ax = plt.subplots(figsize=(7, 5))
    colors = ["#FF6F61", "#6B5B95", "#88B04B", "#F7CAC9", "#92A8D1", "#955251", "#B565A7"]
    class_distribution.plot(kind="bar", ax=ax, color=colors[:len(class_distribution)], edgecolor="black")
    ax.set_title("üìä Distribuci√≥n de Clases", fontsize=14, fontweight="bold", color="#333333")
    ax.set_xlabel("Clase", fontsize=12, fontweight="bold", color="#555555")
    ax.set_ylabel("Frecuencia", fontsize=12, fontweight="bold", color="#555555")
    ax.set_xticklabels(class_distribution.index, rotation=0, fontsize=11)
    ax.grid(axis="y", linestyle="--", alpha=0.7)
    st.pyplot(fig)

    st.write("""Fuente: Blackard, J. (1998). Covertype [Dataset]. UCI Machine Learning Repository. https://doi.org/10.24432/C50K5N.""")

elif capitulo == "Exploraci√≥n de Datos":
    st.header("üîç Exploraci√≥n de Datos")

    if st.checkbox("Mostrar primeras filas"):
        n_rows = st.slider("N√∫mero de filas a mostrar:", 1, len(dataset), 5)
        st.write(f"### Primeras {n_rows} filas del dataset")
        st.write(dataset.head(n_rows))
    
    if st.checkbox("Mostrar informaci√≥n general"):
        st.write("### Informaci√≥n general del dataset")
        st.write("#### Tipos de datos y valores nulos:")
        st.write(dataset.dtypes)
        st.write("#### Valores nulos por columna:")
        st.write(dataset.isnull().sum())
        st.write("#### Estad√≠sticas descriptivas:")
        st.write(dataset.describe())

elif capitulo == "Visualizaci√≥n de Datos":
    st.header("üìä Visualizaci√≥n de Datos")

    chart_type = st.sidebar.selectbox(
        "Selecciona el tipo de gr√°fico:",
        ["Dispersi√≥n", "Distribuci√≥n variable objetivo",
         "Mapa de correlaci√≥n"]
    )

    if chart_type == "Dispersi√≥n" and len(numeric_columns) > 1:
        x_var = st.sidebar.selectbox("Variable X:", numeric_columns)
        y_var = st.sidebar.selectbox("Variable Y:", numeric_columns)
        st.write(f"### Gr√°fico de dispersi√≥n: {x_var} vs {y_var}")
        fig = px.scatter(dataset, x=x_var, y=y_var, title=f"Dispersi√≥n de {x_var} vs {y_var}")
        st.plotly_chart(fig)
        
    elif chart_type == "Distribuci√≥n Variable objetivo":
        st.write("### Distribuci√≥n de la variable objetivo (Cover_Type)")
        fig, ax = plt.subplots(figsize=(8, 6))
        sns.countplot(data=dataset, x='target', palette='viridis', ax=ax)
        ax.set_title("Distribuci√≥n de la variable objetivo (Cover_Type)")
        ax.set_xlabel("Tipo de cobertura")
        ax.set_ylabel("Frecuencia")
        st.pyplot(fig)
    
    elif chart_type == "Mapa de correlaci√≥n" and len(numeric_columns) > 1:
        st.write("### Mapa de correlaci√≥n")
        corr = dataset.corr()
        fig, ax = plt.subplots(figsize=(14, 10))
        sns.heatmap(corr, annot=False, cmap="coolwarm", ax=ax)
        ax.set_title("Mapa de correlaci√≥n")
        st.pyplot(fig)
    
elif capitulo == "Modelos de Clasificaci√≥n":
    st.header("ü§ñ K- Nearest Neighbors")
    st.write("Informaci√≥n del modelo previamente entrenado por el m√©todo K Nearest Neighbors.")

    
    #Informaci√≥n del modelo
    st.write("üìä Par√°metros del Modelo")
    


        
        
#####Aqu√≠
    

    st.header("üß† Modelo Redes Neuronales")
    st.write("Informaci√≥n del modelo previamente entrenado por el m√©todo redes neuronales.")

    st.write("""**Mejores hiperpar√°metros encontrados:** \n
    **depth:** 3 \n
    **epochs:** 5 \n
    **num_units:** 80 \n
    **optimizer:** 'rmsprop' \n
    **activation:** 'tanh' \n
    **batch_size:** 56 \n
    **learning_rate:** 0.0006558000197767294
    
    """)
    
    img = Image.open("Imagen_rendimiento_modelo_redes.jpeg")
    img1 = Image.open("Estructura_modelo_png")
    st.image(img, caption="Gr√°fico de entrenamiento y validaci√≥n del modelo", use_container_width=True)
    st.image(img1, caption="Estructura Modelo Red Neuronal", use_container_width=True)
    # Definir las caracter√≠sticas que necesita el modelo

feature_names = [
    "Elevation", "Aspect", "Slope", "Horizontal_Distance_To_Hydrology",
    "Vertical_Distance_To_Hydrology", "Horizontal_Distance_To_Roadways",
    "Horizontal_Distance_To_Fire_Point"
]

#Rango de valores para las variables
variables_range = {
    "Elevation": {"min": 1850, "max": 4000, "desc": "Elevaci√≥n en metros"},
    "Aspect": {"min": 0, "max": 360, "desc": "Orientaci√≥n en grados de azimut"},
    "Slope": {"min": 0, "max": 60, "desc": "Pendiente en grados"},
    "Horizontal_Distance_To_Hydrology": {"min": 0, "max": 1350, "desc": "Distancia a cuerpos de agua"},
    "Vertical_Distance_To_Hydrology": {"min": -150, "max": 550, "desc": "Diferencia de altura cuerpos de agua"},
    "Horizontal_Distance_To_Roadways": {"min": 0, "max": 7000, "desc": "Distancia a la carretera"},
    "Horizontal_Distance_To_Fire_Point": {"min": 0, "max": 7000, "desc": "Distancia a punto de incendios"}
}

#Ingresar variables para clasificaci√≥n
st.sidebar.header("üìå Ingrese los valores para clasificar el tipo de cobertura:")

valores_usuario = []
for col, info in variables_range.items():
    valor = st.sidebar.slider(
        f"{col} - {info['desc']}",
        min_value=float(info["min"]),
        max_value=float(info["max"]),
        value=(info["min"] + info["max"]) / 2
    )
    valores_usuario.append(valor)

if st.sidebar.button("üîç Clasificar Cobertura"):
    if modelo is not None:
        entrada = np.array(valores_usuario).reshape(1, -1).astype(np.float32)  # Convertir a matriz y float32

        try:
            prediccion = modelo.predict(entrada)  # Hacer la predicci√≥n

            # ‚úÖ Verificar si es un modelo DNN y ajustar salida
            if isinstance(modelo, tf.keras.Model):
                if prediccion.shape[1] > 1:  # Si la salida es multiclase (softmax)
                    prediccion = np.argmax(prediccion, axis=1)  
                else:  # Si es binaria (sigmoid)
                    prediccion = np.round(prediccion).astype(int)

            # ‚úÖ Unificar salida con KNN
            st.sidebar.success(f"üå≤ Tipo de cobertura clasificada: {int(prediccion[0])}")

        except Exception as e:
            st.error(f"‚ö†Ô∏è Error al hacer la predicci√≥n: {e}")
    else:
        st.error("‚ö†Ô∏è No se pudo hacer la clasificaci√≥n porque el modelo no est√° cargado.")




